# FlatQuant æ•°æ®é›†ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•ä¸‹è½½å’Œä½¿ç”¨FlatQuantæ‰€éœ€çš„æ•°æ®é›†ã€‚

## ğŸ“‹ æ•°æ®é›†æ¦‚è§ˆ

FlatQuantéœ€è¦ä¸¤ç±»æ•°æ®é›†ï¼š

### 1. æ ¡å‡†å’Œå›°æƒ‘åº¦è¯„ä¼°æ•°æ®é›†
ç”¨äºæ¨¡å‹æ ¡å‡†å’Œå›°æƒ‘åº¦è¯„ä¼°ï¼š
- **WikiText2**: ç»´åŸºç™¾ç§‘æ–‡æœ¬æ•°æ®é›†
- **C4**: Colossal Clean Crawled Corpus
- **Pile**: The PileéªŒè¯é›†

### 2. å¸¸è¯†é—®ç­”è¯„ä¼°æ•°æ®é›†
ç”¨äºå¸¸è¯†é—®ç­”ä»»åŠ¡è¯„ä¼°ï¼š
- **AI2 ARC**: AI2æ¨ç†æŒ‘æˆ˜èµ›æ•°æ®é›†
- **HellaSwag**: å¸¸è¯†æ¨ç†æ•°æ®é›†
- **LAMBADA**: è¯­è¨€å»ºæ¨¡åŸºå‡†æ•°æ®é›†
- **PIQA**: ç‰©ç†ç›´è§‰é—®ç­”æ•°æ®é›†
- **WinoGrande**: å¸¸è¯†æ¨ç†æ•°æ®é›†

## ğŸš€ å¿«é€Ÿä¸‹è½½

### æ–¹æ³•1: ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd FlatQuant-main

# è¿è¡Œä¸‹è½½è„šæœ¬
./download_datasets.sh
```

### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨Pythonè„šæœ¬

```bash
cd FlatQuant-main

# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
pip install datasets lm-eval

# è¿è¡Œä¸‹è½½è„šæœ¬
python download_datasets.py
```

## ğŸ“ ç›®å½•ç»“æ„

ä¸‹è½½å®Œæˆåï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```
FlatQuant-main/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ wikitext/              # WikiText2æ•°æ®é›†
â”‚   â”œâ”€â”€ allenai/
â”‚   â”‚   â””â”€â”€ c4/               # C4æ•°æ®é›†
â”‚   â”œâ”€â”€ pile-val-backup/      # PileéªŒè¯é›†
â”‚   â”œâ”€â”€ ai2_arc/              # AI2 ARCæ•°æ®é›†
â”‚   â”œâ”€â”€ hellaswag/            # HellaSwagæ•°æ®é›†
â”‚   â”œâ”€â”€ lambada_openai/       # LAMBADAæ•°æ®é›†
â”‚   â”œâ”€â”€ piqa/                 # PIQAæ•°æ®é›†
â”‚   â”œâ”€â”€ winogrande/           # WinoGrandeæ•°æ®é›†
â”‚   â”œâ”€â”€ lm_eval_configs/
â”‚   â”‚   â””â”€â”€ tasks/            # lm_evalé…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ dataset_info.json     # æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
```

## ğŸ”§ æ•°æ®é›†ä½¿ç”¨

### 1. æ ¡å‡†æ•°æ®é›†ä½¿ç”¨

FlatQuantä¼šè‡ªåŠ¨ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹æ ¡å‡†ï¼š

```python
# åœ¨é‡åŒ–è„šæœ¬ä¸­ï¼Œæ•°æ®é›†ä¼šè‡ªåŠ¨åŠ è½½
python quantize_qwen2.5_0.5b.py \
    --cali_dataset wikitext2 \
    --nsamples 128
```

### 2. å›°æƒ‘åº¦è¯„ä¼°

```python
# è¯„ä¼°æ¨¡å‹åœ¨WikiText2ä¸Šçš„å›°æƒ‘åº¦
python main.py \
    --model your_model \
    --eval_ppl \
    --eval_datasets wikitext2 c4
```

### 3. å¸¸è¯†é—®ç­”è¯„ä¼°

```python
# ä½¿ç”¨lm_evalè¿›è¡Œé—®ç­”ä»»åŠ¡è¯„ä¼°
python main.py \
    --model your_model \
    --lm_eval \
    --tasks arc_easy,arc_challenge,hellaswag,piqa,winogrande
```

## ğŸ“Š æ•°æ®é›†è¯¦æƒ…

### WikiText2
- **ç”¨é€”**: æ¨¡å‹æ ¡å‡†å’Œå›°æƒ‘åº¦è¯„ä¼°
- **å¤§å°**: ~2MB
- **æ ¼å¼**: åŸå§‹æ–‡æœ¬
- **é…ç½®**: `wikitext-2-raw-v1`

### C4
- **ç”¨é€”**: æ¨¡å‹æ ¡å‡†å’Œå›°æƒ‘åº¦è¯„ä¼°
- **å¤§å°**: ~1GB
- **æ ¼å¼**: æ¸…ç†åçš„ç½‘é¡µæ–‡æœ¬
- **é…ç½®**: `en`

### AI2 ARC
- **ç”¨é€”**: å¸¸è¯†é—®ç­”è¯„ä¼°
- **å¤§å°**: ~15MB
- **æ ¼å¼**: å¤šé€‰é¢˜
- **ä»»åŠ¡**: `arc_easy`, `arc_challenge`

### HellaSwag
- **ç”¨é€”**: å¸¸è¯†æ¨ç†è¯„ä¼°
- **å¤§å°**: ~30MB
- **æ ¼å¼**: å¥å­è¡¥å…¨
- **ä»»åŠ¡**: `hellaswag`

### LAMBADA
- **ç”¨é€”**: è¯­è¨€å»ºæ¨¡è¯„ä¼°
- **å¤§å°**: ~5MB
- **æ ¼å¼**: å¥å­è¡¥å…¨
- **ä»»åŠ¡**: `lambada_openai`

### PIQA
- **ç”¨é€”**: ç‰©ç†ç›´è§‰è¯„ä¼°
- **å¤§å°**: ~2MB
- **æ ¼å¼**: äºŒé€‰ä¸€é—®é¢˜
- **ä»»åŠ¡**: `piqa`

### WinoGrande
- **ç”¨é€”**: å¸¸è¯†æ¨ç†è¯„ä¼°
- **å¤§å°**: ~10MB
- **æ ¼å¼**: ä»£è¯æ¶ˆè§£
- **ä»»åŠ¡**: `winogrande`

## âš™ï¸ é…ç½®è¯´æ˜

### lm_evalé…ç½®æ–‡ä»¶

è„šæœ¬ä¼šè‡ªåŠ¨å¤åˆ¶å’Œä¿®æ”¹lm_evalé…ç½®æ–‡ä»¶ï¼š

1. **å¤åˆ¶é…ç½®æ–‡ä»¶**: ä»lm_evalå®‰è£…ç›®å½•å¤åˆ¶åˆ°`./datasets/lm_eval_configs/tasks/`
2. **ä¿®æ”¹æ•°æ®é›†è·¯å¾„**: å°†`dataset_path`å­—æ®µä¿®æ”¹ä¸ºæœ¬åœ°è·¯å¾„
3. **æ”¯æŒçš„ä»»åŠ¡**: arc_easy, arc_challenge, hellaswag, lambada_openai, piqa, winogrande

### è‡ªå®šä¹‰é…ç½®

å¦‚æœéœ€è¦ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†è·¯å¾„ï¼Œå¯ä»¥ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š

```yaml
# ç¤ºä¾‹: ./datasets/lm_eval_configs/tasks/arc_easy.yaml
dataset_path: ./datasets/ai2_arc
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. ä¸‹è½½å¤±è´¥
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping huggingface.co

# é‡è¯•ä¸‹è½½
python download_datasets.py
```

### 2. å†…å­˜ä¸è¶³
```bash
# åˆ†æ‰¹ä¸‹è½½æ•°æ®é›†
python download_datasets.py --calibration-only  # åªä¸‹è½½æ ¡å‡†æ•°æ®é›†
python download_datasets.py --qa-only           # åªä¸‹è½½é—®ç­”æ•°æ®é›†
```

### 3. lm_evalé…ç½®é—®é¢˜
```bash
# æ‰‹åŠ¨å®‰è£…lm_eval
pip install lm-eval

# æ£€æŸ¥é…ç½®æ–‡ä»¶
ls ./datasets/lm_eval_configs/tasks/
```

### 4. æ•°æ®é›†è·¯å¾„é—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æ­£ç¡®ä¸‹è½½
ls -la ./datasets/

# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
cat ./datasets/dataset_info.json
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. å¿«é€Ÿæµ‹è¯•
å¯¹äºå¿«é€Ÿæµ‹è¯•ï¼Œå¯ä»¥ä½¿ç”¨è¾ƒå°çš„æ ¡å‡†æ ·æœ¬æ•°ï¼š
```bash
python quantize_qwen2.5_0.5b.py --nsamples 64
```

### 2. é«˜è´¨é‡é‡åŒ–
å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œä½¿ç”¨æ›´å¤šæ ¡å‡†æ ·æœ¬ï¼š
```bash
python quantize_qwen2.5_0.5b.py --nsamples 512
```

### 3. é€‰æ‹©æ€§è¯„ä¼°
åªè¯„ä¼°å¿…è¦çš„ä»»åŠ¡ï¼š
```bash
python main.py --tasks arc_easy,piqa  # åªè¯„ä¼°éƒ¨åˆ†ä»»åŠ¡
```

## ğŸ” éªŒè¯æ•°æ®é›†

ä¸‹è½½å®Œæˆåï¼Œå¯ä»¥éªŒè¯æ•°æ®é›†æ˜¯å¦æ­£ç¡®ï¼š

```bash
# æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
python -c "
from datasets import load_dataset
dataset = load_dataset('./datasets/wikitext')
print(f'WikiText2: {len(dataset[\"train\"])} è®­ç»ƒæ ·æœ¬, {len(dataset[\"validation\"])} éªŒè¯æ ·æœ¬')
"
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: `dataset_download_*.log`
2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸
3. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³
4. å‚è€ƒREADME.mdäº†è§£æ›´å¤šä¿¡æ¯

## ğŸ¯ æœ€ä½³å®è·µ

1. **é¦–æ¬¡ä½¿ç”¨**: å»ºè®®ä¸‹è½½æ‰€æœ‰æ•°æ®é›†
2. **ç”Ÿäº§ç¯å¢ƒ**: æ ¹æ®å®é™…éœ€è¦é€‰æ‹©æ€§ä¸‹è½½
3. **å­˜å‚¨ç©ºé—´**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆçº¦2GBï¼‰
4. **ç½‘ç»œç¯å¢ƒ**: ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
5. **å®šæœŸæ›´æ–°**: å®šæœŸæ£€æŸ¥æ•°æ®é›†æ›´æ–°
