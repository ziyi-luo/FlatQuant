#!/usr/bin/env python3
"""
FlatQuant æ•°æ®é›†éªŒè¯è„šæœ¬
éªŒè¯å·²ä¸‹è½½çš„æ•°æ®é›†æ˜¯å¦æ­£ç¡®
"""

import os
import json
from pathlib import Path
from datasets import load_dataset
import logging

def setup_logging():
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

logger = setup_logging()

# æ•°æ®é›†é…ç½®
DATASETS_CONFIG = {
    "calibration_datasets": {
        "wikitext": {
            "name": "wikitext",
            "config": "wikitext-2-raw-v1",
            "local_dir": "./datasets/wikitext",
            "expected_splits": ["train", "validation"]
        },
        "c4": {
            "name": "allenai/c4",
            "config": "en",
            "local_dir": "./datasets/allenai/c4",
            "expected_splits": ["train", "validation"]
        },
        "pile": {
            "name": "mit-han-lab/pile-val-backup",
            "config": None,
            "local_dir": "./datasets/pile-val-backup",
            "expected_splits": ["validation"]
        }
    },
    "qa_datasets": {
        "ai2_arc": {
            "name": "allenai/ai2_arc",
            "config": None,
            "local_dir": "./datasets/ai2_arc",
            "expected_splits": ["train", "validation", "test"]
        },
        "hellaswag": {
            "name": "Rowan/hellaswag",
            "config": None,
            "local_dir": "./datasets/hellaswag",
            "expected_splits": ["train", "validation"]
        },
        "lambada_openai": {
            "name": "EleutherAI/lambada_openai",
            "config": None,
            "local_dir": "./datasets/lambada_openai",
            "expected_splits": ["train", "validation", "test"]
        },
        "piqa": {
            "name": "ybisk/piqa",
            "config": None,
            "local_dir": "./datasets/piqa",
            "expected_splits": ["train", "validation"]
        },
        "winogrande": {
            "name": "winogrande",
            "config": "winogrande_xl",
            "local_dir": "./datasets/winogrande",
            "expected_splits": ["train", "validation"]
        }
    }
}

def verify_dataset(dataset_info, dataset_type):
    """éªŒè¯å•ä¸ªæ•°æ®é›†"""
    try:
        logger.info(f"éªŒè¯ {dataset_type} æ•°æ®é›†: {dataset_info['name']}")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not Path(dataset_info['local_dir']).exists():
            logger.error(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_info['local_dir']}")
            return False
        
        # å°è¯•åŠ è½½æ•°æ®é›†
        try:
            dataset = load_dataset(dataset_info['local_dir'])
        except Exception as e:
            logger.error(f"âŒ æ— æ³•åŠ è½½æ•°æ®é›†: {str(e)}")
            return False
        
        # æ£€æŸ¥æ•°æ®é›†åˆ†å‰²
        available_splits = list(dataset.keys())
        expected_splits = dataset_info['expected_splits']
        
        missing_splits = set(expected_splits) - set(available_splits)
        if missing_splits:
            logger.warning(f"âš ï¸ ç¼ºå°‘æ•°æ®é›†åˆ†å‰²: {missing_splits}")
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        logger.info(f"âœ… æ•°æ®é›†éªŒè¯æˆåŠŸ: {dataset_info['name']}")
        for split_name in available_splits:
            split_data = dataset[split_name]
            logger.info(f"   - {split_name}: {len(split_data)} æ ·æœ¬")
            if hasattr(split_data, 'features'):
                logger.info(f"     ç‰¹å¾: {list(split_data.features.keys())}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ éªŒè¯ {dataset_type} æ•°æ®é›†å¤±è´¥: {dataset_info['name']}")
        logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        return False

def verify_lm_eval_configs():
    """éªŒè¯lm_evalé…ç½®æ–‡ä»¶"""
    try:
        logger.info("éªŒè¯lm_evalé…ç½®æ–‡ä»¶...")
        
        config_dir = Path("./datasets/lm_eval_configs/tasks")
        if not config_dir.exists():
            logger.error(f"âŒ lm_evalé…ç½®ç›®å½•ä¸å­˜åœ¨: {config_dir}")
            return False
        
        # æ£€æŸ¥å¿…è¦çš„é…ç½®æ–‡ä»¶
        required_configs = [
            "arc/arc_easy.yaml",
            "arc/arc_challenge.yaml",
            "hellaswag/hellaswag.yaml",
            "lambada/lambada_openai.yaml",
            "piqa/piqa.yaml",
            "winogrande/default.yaml"
        ]
        
        missing_configs = []
        for config_file in required_configs:
            config_path = config_dir / config_file
            if not config_path.exists():
                missing_configs.append(config_file)
            else:
                logger.info(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")
        
        if missing_configs:
            logger.warning(f"âš ï¸ ç¼ºå°‘é…ç½®æ–‡ä»¶: {missing_configs}")
            return False
        
        logger.info("âœ… lm_evalé…ç½®æ–‡ä»¶éªŒè¯æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ lm_evalé…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")
        return False

def check_dataset_info():
    """æ£€æŸ¥æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶"""
    try:
        info_file = Path("./datasets/dataset_info.json")
        if not info_file.exists():
            logger.warning("âš ï¸ æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        with open(info_file, 'r', encoding='utf-8') as f:
            info = json.load(f)
        
        logger.info("âœ… æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶å­˜åœ¨")
        logger.info(f"   ä¸‹è½½æ—¶é—´: {info.get('download_time', 'æœªçŸ¥')}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” FlatQuant æ•°æ®é›†éªŒè¯")
    print("=" * 40)
    
    # æ£€æŸ¥æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
    check_dataset_info()
    
    # éªŒè¯æ ¡å‡†æ•°æ®é›†
    print("\nğŸ“Š éªŒè¯æ ¡å‡†å’Œå›°æƒ‘åº¦è¯„ä¼°æ•°æ®é›†...")
    calibration_success = 0
    calibration_total = len(DATASETS_CONFIG["calibration_datasets"])
    
    for dataset_name, dataset_info in DATASETS_CONFIG["calibration_datasets"].items():
        if verify_dataset(dataset_info, "æ ¡å‡†"):
            calibration_success += 1
    
    # éªŒè¯é—®ç­”æ•°æ®é›†
    print("\nâ“ éªŒè¯å¸¸è¯†é—®ç­”è¯„ä¼°æ•°æ®é›†...")
    qa_success = 0
    qa_total = len(DATASETS_CONFIG["qa_datasets"])
    
    for dataset_name, dataset_info in DATASETS_CONFIG["qa_datasets"].items():
        if verify_dataset(dataset_info, "é—®ç­”"):
            qa_success += 1
    
    # éªŒè¯lm_evalé…ç½®
    print("\nâš™ï¸ éªŒè¯lm_evalé…ç½®æ–‡ä»¶...")
    lm_eval_success = verify_lm_eval_configs()
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 40)
    print("ğŸ“‹ éªŒè¯ç»“æœæ±‡æ€»:")
    print(f"   æ ¡å‡†æ•°æ®é›†: {calibration_success}/{calibration_total} æ­£å¸¸")
    print(f"   é—®ç­”æ•°æ®é›†: {qa_success}/{qa_total} æ­£å¸¸")
    print(f"   lm_evalé…ç½®: {'âœ… æ­£å¸¸' if lm_eval_success else 'âŒ å¼‚å¸¸'}")
    
    total_success = calibration_success + qa_success
    total_datasets = calibration_total + qa_total
    
    if total_success == total_datasets and lm_eval_success:
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®é›†éªŒè¯é€šè¿‡ï¼")
        print("   ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨FlatQuantè¿›è¡Œæ¨¡å‹é‡åŒ–äº†")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ•°æ®é›†éªŒè¯å¤±è´¥")
        print("   è¯·è¿è¡Œ ./download_datasets.sh é‡æ–°ä¸‹è½½æ•°æ®é›†")
        
        if calibration_success < calibration_total:
            print("   å»ºè®®é‡æ–°ä¸‹è½½æ ¡å‡†æ•°æ®é›†")
        if qa_success < qa_total:
            print("   å»ºè®®é‡æ–°ä¸‹è½½é—®ç­”æ•°æ®é›†")
        if not lm_eval_success:
            print("   å»ºè®®é‡æ–°è®¾ç½®lm_evalé…ç½®")

if __name__ == "__main__":
    main()
